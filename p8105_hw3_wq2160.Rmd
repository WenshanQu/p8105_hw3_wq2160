---
title: "p8105_hw3_wq2160"
author: "Wenshan Qu (wq2160)"
date: "10/18/2021"
output: github_document
---

```{r, include=FALSE}
library(tidyverse)
```

Initial Display Settings

```{r}
knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

load the `instacart` data.

```{r}
library(p8105.datasets)
data("instacart")
```


**Description**

This data set contains `r nrow(distinct(instacart, order_id))` orders information, with `r nrow(instacart)` rows and `r ncol(instacart)` columns. The key variables in this data set including `r names(instacart)`. 

To give a simple example on how to illustrate this chart, we could take the order with id = 1. `r ins_eg = filter(instacart, order_id == "1") ` For this order, number of `r nrow(ins_eg)` items was purchased, with item names  `r pull(ins_eg, product_name)` and item id `r pull(ins_eg, product_id)`. For these items, the aisle_id, department_id and aisle name were provided to locate the product. Also, we can get the information fo the customer purchase behavior, such as the order these items were added to the cart, purchase time, times and intervals of reordering each item.

**1.1 Aisle information**

```{r}
instacart %>% 
  count(aisle) %>% 
    arrange(desc(n))
```

There are `r instacart %>% distinct(aisle) %>% count()` aisles, and the most items are ordered from the **fresh vegetables** aisle. "fresh fruits", "packaged vegetables fruits" and "yogurt" are also popular aisles.

**1.2 Aisle plot**

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(
    title = "Number of items ordered in each aisle",
    x = "Aisle",
    y = "Number of items"
  )
```

**1.3 Popular product in aisles**

```{r}
aisle_df = 
  instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  arrange(aisle, desc(n)) %>% 
  filter(row_number() <= 3) %>% 
  rename(most_popular_product = product_name, ordered_times = n) %>% 
  knitr::kable(digits = 2)

aisle_df
```

**1.4 Product and day** 

```{r message=FALSE}
day_df = 
  instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_hour = mean(order_hour_of_day)
  ) %>% 
  mutate(
    order_dow = recode(order_dow, "0" = "Sunday", "1" = "Monday", "2" = "Tuesday", "3" = "Wednesday", "4" = "Thursday", "5" = "Friday", "6" = "Saturday")
  ) %>% 
  pivot_wider(
    names_from = "order_dow",
    values_from = "mean_hour"
  ) %>% 
  knitr::kable(digits = 2)

day_df
```


## Problem 2

Load the data set `BRFSS`.
```{r}
data("brfss_smart2010")
```

**2.1 Data cleaning**

```{r}
tidy_brfss = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  drop_na(response) %>% ## Except 5 responses, there are only null value, so we use drop_na.
  mutate(
    response = factor(response),
    response = fct_relevel(response, "Poor", "Fair", "Good", "Very good", "Excellent")
  ) %>% 
  arrange(response)

tidy_brfss
```

**2.2 2002 locations**

```{r}
state_obs_2002 = 
  tidy_brfss %>% 
  filter(year == "2002") %>% 
  group_by(locationabbr) %>% 
  summarize(county = n_distinct(locationdesc)) %>% 
  filter(county >= 7) %>% 
  knitr::kable(aligh = "c")

state_obs_2002
```

In 2002, 6 states including CT, FL, MA, NC, NJ and PA were observed at 7 or more locations.

```{r}
state_obs_2010 = 
  tidy_brfss %>% 
  filter(year == "2010") %>% 
  group_by(locationabbr) %>% 
  summarize(county = n_distinct(locationdesc)) %>% 
  filter(county >= 7) %>% 
  knitr::kable(aligh = "c")

state_obs_2010
```

In 2010, 14 states including CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX and WA were observed at 7 or more locations.

**2.3 Excellent plot**

```{r message=FALSE}
tidy_brfss %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(
    state_mean = mean(data_value, na.rm = TRUE)
  ) %>% 
  ggplot(aes(x = year, y = state_mean, color = locationabbr)) +
  geom_line() +
  theme(legend.position = "right") +
  viridis::scale_color_viridis(
    name = "state",
    discrete = TRUE
  ) +
  labs(
    title = "Spaghetti plot within each state over time",
    x = "Year",
    y = "Average value in each state"
  )
```

**2.4 NY state**

```{r}
tidy_brfss %>% 
  filter(
    locationabbr == "NY",
    year %in% c(2006, 2010)
  ) %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  mutate(county = substring(county, 6)) %>% 
  group_by(year, county) %>% 
  ggplot(aes(x = response, y = data_value, fill = county)) +
  geom_col(position = "dodge") +
  facet_grid(. ~ year) +
  labs(
    title = "Value for responses among locations in NY for 2006 and 2010",
    x = "Response",
    y = "Data value for responses"
  ) 
```

I also want to show the graph without county facet like this:

```{r}
tidy_brfss %>% 
  filter(
    locationabbr == "NY",
    year %in% c(2006, 2010)
  ) %>%
  ggplot(aes(x = response, y = data_value, fill = response)) + 
  geom_boxplot() + 
  labs(
      title = "Distribution of data value for responses in NY",
      x = "Response",
      y = "Data value"
      ) +
  facet_grid(. ~ year)
```

The reason that I used two kinds of graphs to illustrate this problem is that I am not sure about the true meaning of `among locations in NY` mentioned in the problem. But given these two graphs --- with or without county facet --- are useful, I showed both of them here.


## Problem 3

**3.1 Tidy data**

```{r}
accel_df = 
  read.csv("./accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    values_to = "observation"
  ) %>% 
  mutate(
    day = factor(day),
    day = fct_relevel(day, "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
  ) %>% 
  mutate(
    day_type = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "Weekday",
      day %in% c("Saturday", "Sunday") ~ "Weekend"
    )
  ) %>% 
  select(week, day_id, day, day_type, everything()) %>% 
  arrange(week, day)

accel_df
```

There are `r names(accel_df)` 6 variables after tidying the data. We create a new variable "day_type" according to "day" values, and we pivoted longer this dataset. Finally, there are `r nrow(accel_df)` rows and `r ncol(accel_df)` columns in this dataset. There are `r nrow(distinct(accel_df, week))` weeks, and in each week, there are `r nrow(distinct(accel_df, day))` days. Also, for each day, there are 1440 observations.

**3.2 Total activity**

```{r message=FALSE}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(total_of_day = sum(observation)) %>% 
  pivot_wider(
    names_from = "day", 
    values_from = "total_of_day"
  ) %>% 
  knitr::kable()
```

I could not see apparent trend in this chart. 

Little trend has been shown that for the first 3 weeks, weekends have higher activity than weekdays, while for the 4th and 5th week, this situation reversed. 

What is also worth noticing that for the Saturdays in week 4 and 5, the sum is 1440, which means for each minute in the day, the observation is 1, which is really uncommon. I assume that the device may collapse through these 2 days. 

And if we view this chart horizontally, there exists a slightly increasing trend for activity counts from week 1 to week 5.

**3.3 24-hour activity** 

```{r}
accel_df %>% 
  mutate(
    activity = substring(activity, 10),
    activity = as.integer(activity)
  ) %>% 
  ggplot(aes(x = activity, y = observation, color = day)) +
  geom_line() +
  scale_x_continuous(
    breaks = c(0, 120, 240, 360, 480, 600, 720, 840, 960, 1080, 1200, 1320, 1440),
    labels = c("0", "2", "4", "6", "8", "10", "12", "14", "16", "18", "20", "22", "24")
  ) +
  labs(
        title = "24-hour Activity Time Courses for Each Day ",
        x = "Time of Day (hour)",
        y = "Activity Level"
  ) +
  theme(legend.position = "bottom")
```

We can see from this graph that: 

1) Generally, on weekends, the patient shows lower activity level than weekdays, except on Sunday noon around 11:00 AM, there is a significantly higher activity level than any other days at this time point;

2) For all the days in a week, the most "active" time for this individual appears between 19:00 and 22:00, and the most "inactive" time lies betweeen 0:00 to 4:00, which I assume should be attributed to the sleep.